{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143604b6-5931-40ab-8b4b-5c926260902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1240695d-53f7-4460-9571-5c99d6281351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 06:59:14,779 INFO spark.SparkContext: Running Spark version 3.3.0\n",
      "2022-10-07 06:59:14,808 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-10-07 06:59:15,007 INFO resource.ResourceUtils: ==============================================================\n",
      "2022-10-07 06:59:15,008 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\n",
      "2022-10-07 06:59:15,009 INFO resource.ResourceUtils: ==============================================================\n",
      "2022-10-07 06:59:15,009 INFO spark.SparkContext: Submitted application: spark_etl_demo\n",
      "2022-10-07 06:59:15,046 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "2022-10-07 06:59:15,063 INFO resource.ResourceProfile: Limiting resource is cpu\n",
      "2022-10-07 06:59:15,063 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\n",
      "2022-10-07 06:59:15,168 INFO spark.SecurityManager: Changing view acls to: jovyan\n",
      "2022-10-07 06:59:15,169 INFO spark.SecurityManager: Changing modify acls to: jovyan\n",
      "2022-10-07 06:59:15,169 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "2022-10-07 06:59:15,170 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "2022-10-07 06:59:15,171 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jovyan); groups with view permissions: Set(); users  with modify permissions: Set(jovyan); groups with modify permissions: Set()\n",
      "2022-10-07 06:59:15,600 INFO util.Utils: Successfully started service 'sparkDriver' on port 39711.\n",
      "2022-10-07 06:59:15,669 INFO spark.SparkEnv: Registering MapOutputTracker\n",
      "2022-10-07 06:59:15,713 INFO spark.SparkEnv: Registering BlockManagerMaster\n",
      "2022-10-07 06:59:15,729 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "2022-10-07 06:59:15,730 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "2022-10-07 06:59:15,734 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "2022-10-07 06:59:15,770 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-e5a7e49e-1626-4876-9dff-3b964382cee5\n",
      "2022-10-07 06:59:15,793 INFO memory.MemoryStore: MemoryStore started with capacity 1048.8 MiB\n",
      "2022-10-07 06:59:15,813 INFO spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "2022-10-07 06:59:15,874 INFO util.log: Logging initialized @3503ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "2022-10-07 06:59:16,059 INFO server.Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 11.0.16+8-post-Ubuntu-0ubuntu120.04\n",
      "2022-10-07 06:59:16,078 INFO server.Server: Started @3709ms\n",
      "2022-10-07 06:59:16,107 INFO server.AbstractConnector: Started ServerConnector@10942630{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}\n",
      "2022-10-07 06:59:16,107 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "2022-10-07 06:59:16,188 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2d1182c6{/,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,440 INFO executor.Executor: Starting executor ID driver on host jupyter-831948-0.jupyter-831948.user-pengfei.svc.cluster.local\n",
      "2022-10-07 06:59:16,448 INFO executor.Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "2022-10-07 06:59:16,480 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38927.\n",
      "2022-10-07 06:59:16,480 INFO netty.NettyBlockTransferService: Server created on jupyter-831948-0.jupyter-831948.user-pengfei.svc.cluster.local:38927\n",
      "2022-10-07 06:59:16,482 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "2022-10-07 06:59:16,487 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, jupyter-831948-0.jupyter-831948.user-pengfei.svc.cluster.local, 38927, None)\n",
      "2022-10-07 06:59:16,490 INFO storage.BlockManagerMasterEndpoint: Registering block manager jupyter-831948-0.jupyter-831948.user-pengfei.svc.cluster.local:38927 with 1048.8 MiB RAM, BlockManagerId(driver, jupyter-831948-0.jupyter-831948.user-pengfei.svc.cluster.local, 38927, None)\n",
      "2022-10-07 06:59:16,492 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, jupyter-831948-0.jupyter-831948.user-pengfei.svc.cluster.local, 38927, None)\n",
      "2022-10-07 06:59:16,493 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, jupyter-831948-0.jupyter-831948.user-pengfei.svc.cluster.local, 38927, None)\n",
      "2022-10-07 06:59:16,735 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@2d1182c6{/,null,STOPPED,@Spark}\n",
      "2022-10-07 06:59:16,736 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2d1aa07d{/jobs,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,741 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4af750cb{/jobs/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,746 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@417d685c{/jobs/job,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,759 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@33c19f66{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,760 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48446437{/stages,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,761 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b4aeaeb{/stages/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,765 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@61b035c4{/stages/stage,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,771 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50198b9c{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,772 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cee1685{/stages/pool,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,773 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cb2f0c5{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,774 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1c6ebf87{/storage,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,775 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4985f459{/storage/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,779 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6a96b49{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,780 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@625050f0{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,782 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@535dbb44{/environment,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,786 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d2d97c8{/environment/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,787 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b5d7a9{/executors,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,788 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ebe8117{/executors/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,795 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@28af8674{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,797 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b8133e7{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,819 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@47b48af0{/static,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,824 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@94359d6{/,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,825 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45e37c52{/api,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,826 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@67158043{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,830 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@488370d1{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "2022-10-07 06:59:16,836 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@28493a20{/metrics/json,null,AVAILABLE,@Spark}\n"
     ]
    }
   ],
   "source": [
    "local=True\n",
    "if local:\n",
    "    spark=SparkSession.builder.master(\"local[4]\") \\\n",
    "                  .appName(\"spark_etl_demo\").getOrCreate()\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"spark_etl_demo\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\",os.environ[\"IMAGE_NAME\"]) \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .config(\"spark.executor.instances\", \"4\") \\\n",
    "                      .config(\"spark.executor.memory\",\"2g\") \\\n",
    "                      .config(\"spark.driver.memory\",\"2g\") \\\n",
    "                      .enableHiveSupport() \\\n",
    "                      .getOrCreate()\n",
    "    \n",
    "def set_log_level(spark_session,log_level:str):\n",
    "    logger = spark_session.sparkContext._jvm.org.apache.log4j\n",
    "    if log_level==\"INFO\":\n",
    "        logger_level = logger.Level.INFO\n",
    "    elif log_level==\"WARN\":\n",
    "        logger_level = logger.Level.WARN\n",
    "    elif log_level==\"ERROR\":\n",
    "        logger_level = logger.Level.ERROR\n",
    "    else:\n",
    "        raise ValueError(\"The log_level must be INFO, WARN or ERROR\")\n",
    "    logger.LogManager.getLogger(\"org\").setLevel(logger_level)\n",
    "    logger.LogManager.getLogger(\"akka\").setLevel(logger_level)\n",
    "    \n",
    "set_log_level(spark,\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8c419b-2e38-4ee7-8d6f-4a3e7faefcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir=\"s3a://pengfei\"\n",
    "parquet_file_name=\"diffusion/data_format/sf_fire/parquet/raw\"\n",
    "data_path=f\"{work_dir}/{parquet_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab0756-bd7a-41f6-bf38-70289420610f",
   "metadata": {},
   "source": [
    "# Step 1: Prepare source dataframe\n",
    "\n",
    "Use spark context to read a parquet file and return a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1731e55-b6f7-4b93-ae85-0695405013e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=spark.read.parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a6b079-e3d1-4503-9c30-aa11d888d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frame has : 5500519 rows and 34 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row_nb=df_raw.count()\n",
    "col_nb=len(df_raw.columns)\n",
    "\n",
    "print(f\"data frame has : {row_nb} rows and {col_nb} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a49bb7c4-cc3f-467f-8fe0-efbcbd7df0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "|IncidentNumber|            CallType|  CallDate|         City|NeighborhoodDistrict|\n",
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "|      21017645|              Alarms|02/08/2021|San Francisco|           Lakeshore|\n",
      "|      21017596|              Alarms|02/08/2021|San Francisco|         Mission Bay|\n",
      "|      21017578|Citizen Assist / ...|02/08/2021|San Francisco|              Marina|\n",
      "|      21017552|               Other|02/08/2021|    Daly City|                None|\n",
      "|      21017398|              Alarms|02/07/2021|San Francisco|   Lone Mountain/USF|\n",
      "|      21017307|              Alarms|02/07/2021|San Francisco|           Japantown|\n",
      "|      21017263|        Outside Fire|02/07/2021|San Francisco|Bayview Hunters P...|\n",
      "|      21017206|              Alarms|02/07/2021|San Francisco| Castro/Upper Market|\n",
      "|      21017173|    Medical Incident|02/07/2021|San Francisco|             Mission|\n",
      "|      21017065|              Alarms|02/07/2021|San Francisco|           Japantown|\n",
      "|      21017021|              Alarms|02/07/2021|San Francisco|           Lakeshore|\n",
      "|      21016911|              Alarms|02/06/2021|San Francisco|     South of Market|\n",
      "|      21016646|      Structure Fire|02/06/2021|San Francisco|        Potrero Hill|\n",
      "|      21016635|              Alarms|02/06/2021|San Francisco|        Potrero Hill|\n",
      "|      21016610|              Alarms|02/06/2021|San Francisco|      Haight Ashbury|\n",
      "|      21016433|              Alarms|02/05/2021|San Francisco|Bayview Hunters P...|\n",
      "|      21016151|        Outside Fire|02/05/2021|Hunters Point|Bayview Hunters P...|\n",
      "|      21016122|    Medical Incident|02/05/2021|San Francisco|     South of Market|\n",
      "|      21016489|    Medical Incident|02/05/2021|San Francisco|     South of Market|\n",
      "|      21017540|    Medical Incident|02/08/2021|San Francisco|          Tenderloin|\n",
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=df_raw.select(\"IncidentNumber\", \"CallType\", \"CallDate\",\"City\",\"NeighborhoodDistrict\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b3e5b-ecd3-4cd6-b674-c619c84fbc19",
   "metadata": {},
   "source": [
    "# Step2: Create a table in hive metastore\n",
    "\n",
    "Use the spark dataframe to create a hive table in the hive metastore. So we can reuse it for later. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bae3b20b-ffcb-4860-bd98-b1eb0684d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name=\"sf_fire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5df66c6-e677-4081-84ab-9c302030a656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 15:38:36,952 INFO hive.log: Updating table stats fast for sf_fire\n",
      "2022-09-15 15:38:36,953 INFO hive.log: Updated size of table sf_fire to 372045123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_str = ', '.join([' '.join(x) for x in df.dtypes])\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS {table_name}\n",
    "({schema_str})\n",
    "STORED as parquet LOCATION '{data_path}'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe9ee03-c83a-43db-b8a3-1a65f3c2c282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|  sf_fire|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables;').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fbab0-b7ab-425b-b187-bada38a8b5fd",
   "metadata": {},
   "source": [
    "Now your hive table has been created. In the backgroud, if you enabled the listener, the metadata of this hive table will be uploaded to our [data catalog](https://atlas.lab.sspcloud.fr/index.html#!/search). So you can find all your hive table easily even you don't have notebook anymore.\n",
    "\n",
    "You can try to use the search engine of our [data catalog](https://atlas.lab.sspcloud.fr/index.html#!/search) to find your table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4480a72-9c1c-4d91-bb30-2b7503d0b66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "|IncidentNumber|            CallType|  CallDate|         City|NeighborhoodDistrict|\n",
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "|      21017645|              Alarms|02/08/2021|San Francisco|           Lakeshore|\n",
      "|      21017596|              Alarms|02/08/2021|San Francisco|         Mission Bay|\n",
      "|      21017578|Citizen Assist / ...|02/08/2021|San Francisco|              Marina|\n",
      "|      21017552|               Other|02/08/2021|    Daly City|                None|\n",
      "|      21017398|              Alarms|02/07/2021|San Francisco|   Lone Mountain/USF|\n",
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"SELECT * FROM {table_name} limit 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33a2b084-c2ea-4b7e-82fa-92f269fee9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            CallType|incidentNum|\n",
      "+--------------------+-----------+\n",
      "|    Medical Incident|    3596332|\n",
      "|      Structure Fire|     681179|\n",
      "|              Alarms|     599263|\n",
      "|   Traffic Collision|     224909|\n",
      "|               Other|      87468|\n",
      "|Citizen Assist / ...|      82173|\n",
      "|        Outside Fire|      68491|\n",
      "|        Water Rescue|      28253|\n",
      "|        Vehicle Fire|      25512|\n",
      "|Gas Leak (Natural...|      22961|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"select CallType, count(IncidentNumber) as incidentNum from {table_name} group by CallType order by incidentNum desc limit 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de8076e4-2418-44d7-870d-c91c0b5904e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|NeighborhoodDistrict|incidentNum|\n",
      "+--------------------+-----------+\n",
      "|          Tenderloin|     733360|\n",
      "|     South of Market|     531853|\n",
      "|             Mission|     498262|\n",
      "|Financial Distric...|     371420|\n",
      "|Bayview Hunters P...|     298034|\n",
      "|     Sunset/Parkside|     213810|\n",
      "|    Western Addition|     201971|\n",
      "|            Nob Hill|     181346|\n",
      "|      Outer Richmond|     146711|\n",
      "|        Hayes Valley|     135540|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"select NeighborhoodDistrict, count(IncidentNumber) as incidentNum from {table_name} group by NeighborhoodDistrict order by incidentNum desc limit 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6130d-146e-47fc-b264-a08418a33f9c",
   "metadata": {},
   "source": [
    "# Step 3. Drop table \n",
    "\n",
    "You can delete your table if you don't need it anymore. You will notice the metadata of the deleted table are `removed` from the data catalog too.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f4d2753-af8b-4203-b4c4-bd79b7c39954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"drop table if exists {table_name}\"\"\").show()\n",
    "spark.sql('show tables;').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1c0d2-4dbf-447a-b80b-34a52d2d07a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

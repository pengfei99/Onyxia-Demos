{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143604b6-5931-40ab-8b4b-5c926260902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1240695d-53f7-4460-9571-5c99d6281351",
   "metadata": {},
   "outputs": [],
   "source": [
    "local=False\n",
    "if local:\n",
    "    spark=SparkSession.builder.master(\"local[4]\") \\\n",
    "                  .appName(\"spark_etl_demo\").getOrCreate()\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"spark_etl_demo\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\",os.environ[\"IMAGE_NAME\"]) \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .config(\"spark.executor.instances\", \"4\") \\\n",
    "                      .config(\"spark.executor.memory\",\"4g\") \\\n",
    "                      .config(\"spark.driver.memory\",\"8g\") \\\n",
    "                      .enableHiveSupport() \\\n",
    "                      .getOrCreate()\n",
    "    \n",
    "def set_log_level(spark_session,log_level:str):\n",
    "    logger = spark_session.sparkContext._jvm.org.apache.log4j\n",
    "    if log_level==\"INFO\":\n",
    "        logger_level = logger.Level.INFO\n",
    "    elif log_level==\"WARN\":\n",
    "        logger_level = logger.Level.WARN\n",
    "    elif log_level==\"ERROR\":\n",
    "        logger_level = logger.Level.ERROR\n",
    "    else:\n",
    "        raise ValueError(\"The log_level must be INFO, WARN or ERROR\")\n",
    "    logger.LogManager.getLogger(\"org\").setLevel(logger_level)\n",
    "    logger.LogManager.getLogger(\"akka\").setLevel(logger_level)\n",
    "    \n",
    "set_log_level(spark,\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8c419b-2e38-4ee7-8d6f-4a3e7faefcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir=\"s3a://pengfei\"\n",
    "parquet_file_name=\"diffusion/data_format/sf_fire/parquet/raw\"\n",
    "data_path=f\"{work_dir}/{parquet_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab0756-bd7a-41f6-bf38-70289420610f",
   "metadata": {},
   "source": [
    "# Step 1: Prepare source dataframe\n",
    "\n",
    "Use spark context to read a parquet file and return a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1731e55-b6f7-4b93-ae85-0695405013e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=spark.read.parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a6b079-e3d1-4503-9c30-aa11d888d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frame has : 5500519 rows and 34 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row_nb=df_raw.count()\n",
    "col_nb=len(df_raw.columns)\n",
    "\n",
    "print(f\"data frame has : {row_nb} rows and {col_nb} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a49bb7c4-cc3f-467f-8fe0-efbcbd7df0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "|IncidentNumber|            CallType|  CallDate|         City|NeighborhoodDistrict|\n",
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "|      21017645|              Alarms|02/08/2021|San Francisco|           Lakeshore|\n",
      "|      21017596|              Alarms|02/08/2021|San Francisco|         Mission Bay|\n",
      "|      21017578|Citizen Assist / ...|02/08/2021|San Francisco|              Marina|\n",
      "|      21017552|               Other|02/08/2021|    Daly City|                None|\n",
      "|      21017398|              Alarms|02/07/2021|San Francisco|   Lone Mountain/USF|\n",
      "|      21017307|              Alarms|02/07/2021|San Francisco|           Japantown|\n",
      "|      21017263|        Outside Fire|02/07/2021|San Francisco|Bayview Hunters P...|\n",
      "|      21017206|              Alarms|02/07/2021|San Francisco| Castro/Upper Market|\n",
      "|      21017173|    Medical Incident|02/07/2021|San Francisco|             Mission|\n",
      "|      21017065|              Alarms|02/07/2021|San Francisco|           Japantown|\n",
      "|      21017021|              Alarms|02/07/2021|San Francisco|           Lakeshore|\n",
      "|      21016911|              Alarms|02/06/2021|San Francisco|     South of Market|\n",
      "|      21016646|      Structure Fire|02/06/2021|San Francisco|        Potrero Hill|\n",
      "|      21016635|              Alarms|02/06/2021|San Francisco|        Potrero Hill|\n",
      "|      21016610|              Alarms|02/06/2021|San Francisco|      Haight Ashbury|\n",
      "|      21016433|              Alarms|02/05/2021|San Francisco|Bayview Hunters P...|\n",
      "|      21016151|        Outside Fire|02/05/2021|Hunters Point|Bayview Hunters P...|\n",
      "|      21016122|    Medical Incident|02/05/2021|San Francisco|     South of Market|\n",
      "|      21016489|    Medical Incident|02/05/2021|San Francisco|     South of Market|\n",
      "|      21017540|    Medical Incident|02/08/2021|San Francisco|          Tenderloin|\n",
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=df_raw.select(\"IncidentNumber\", \"CallType\", \"CallDate\",\"City\",\"NeighborhoodDistrict\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b3e5b-ecd3-4cd6-b674-c619c84fbc19",
   "metadata": {},
   "source": [
    "# Step2: Create a table in hive metastore\n",
    "\n",
    "Use the spark dataframe to create a hive table in the hive metastore. So we can reuse it for later. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bae3b20b-ffcb-4860-bd98-b1eb0684d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name=\"sf_fire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5df66c6-e677-4081-84ab-9c302030a656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 15:38:36,952 INFO hive.log: Updating table stats fast for sf_fire\n",
      "2022-09-15 15:38:36,953 INFO hive.log: Updated size of table sf_fire to 372045123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_str = ', '.join([' '.join(x) for x in df.dtypes])\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS {table_name}\n",
    "({schema_str})\n",
    "STORED as parquet LOCATION '{data_path}'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe9ee03-c83a-43db-b8a3-1a65f3c2c282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|  sf_fire|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables;').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fbab0-b7ab-425b-b187-bada38a8b5fd",
   "metadata": {},
   "source": [
    "Now your hive table has been created. In the backgroud, if you enabled the listener, the metadata of this hive table will be uploaded to our [data catalog](https://atlas.lab.sspcloud.fr/index.html#!/search). So you can find all your hive table easily even you don't have notebook anymore.\n",
    "\n",
    "You can try to use the search engine of our [data catalog](https://atlas.lab.sspcloud.fr/index.html#!/search) to find your table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4480a72-9c1c-4d91-bb30-2b7503d0b66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "|IncidentNumber|            CallType|  CallDate|         City|NeighborhoodDistrict|\n",
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "|      21017645|              Alarms|02/08/2021|San Francisco|           Lakeshore|\n",
      "|      21017596|              Alarms|02/08/2021|San Francisco|         Mission Bay|\n",
      "|      21017578|Citizen Assist / ...|02/08/2021|San Francisco|              Marina|\n",
      "|      21017552|               Other|02/08/2021|    Daly City|                None|\n",
      "|      21017398|              Alarms|02/07/2021|San Francisco|   Lone Mountain/USF|\n",
      "+--------------+--------------------+----------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"SELECT * FROM {table_name} limit 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33a2b084-c2ea-4b7e-82fa-92f269fee9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            CallType|incidentNum|\n",
      "+--------------------+-----------+\n",
      "|    Medical Incident|    3596332|\n",
      "|      Structure Fire|     681179|\n",
      "|              Alarms|     599263|\n",
      "|   Traffic Collision|     224909|\n",
      "|               Other|      87468|\n",
      "|Citizen Assist / ...|      82173|\n",
      "|        Outside Fire|      68491|\n",
      "|        Water Rescue|      28253|\n",
      "|        Vehicle Fire|      25512|\n",
      "|Gas Leak (Natural...|      22961|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"select CallType, count(IncidentNumber) as incidentNum from {table_name} group by CallType order by incidentNum desc limit 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de8076e4-2418-44d7-870d-c91c0b5904e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|NeighborhoodDistrict|incidentNum|\n",
      "+--------------------+-----------+\n",
      "|          Tenderloin|     733360|\n",
      "|     South of Market|     531853|\n",
      "|             Mission|     498262|\n",
      "|Financial Distric...|     371420|\n",
      "|Bayview Hunters P...|     298034|\n",
      "|     Sunset/Parkside|     213810|\n",
      "|    Western Addition|     201971|\n",
      "|            Nob Hill|     181346|\n",
      "|      Outer Richmond|     146711|\n",
      "|        Hayes Valley|     135540|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"select NeighborhoodDistrict, count(IncidentNumber) as incidentNum from {table_name} group by NeighborhoodDistrict order by incidentNum desc limit 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6130d-146e-47fc-b264-a08418a33f9c",
   "metadata": {},
   "source": [
    "# Step 3. Drop table \n",
    "\n",
    "You can delete your table if you don't need it anymore. You will notice the metadata of the deleted table are `removed` from the data catalog too.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f4d2753-af8b-4203-b4c4-bd79b7c39954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"drop table if exists {table_name}\"\"\").show()\n",
    "spark.sql('show tables;').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1c0d2-4dbf-447a-b80b-34a52d2d07a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
